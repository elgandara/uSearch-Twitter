{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uSearch \n",
    "This search engine will allow users to find other Twitter users to follow. The user may search based on the tweet content. Users will be able to enter a query that will be matched against our Twitter corpus and output ranked results that best fit the user's query. uSearch also features a query option of allowing the user to search for tweets from a specified user by starting their query with an '@' symbol.  \n",
    "\n",
    "# Approach \n",
    "Our approach was to read in tweets from a pre-defined dataset, normalize the data, create an inverted index, apply a ranking algorithm, and output results. The user will be asked whether they are searching for a tweets matching their query content or for a specific user's tweets. Tweets are entered into the inverted index using the stemmed equivalence of the words in the tweet. For stemming the words, we used the nltk module's PorterStemmer library.\n",
    "\n",
    "# Key Insights \n",
    "a) A larger corpus allows for more diverse results. <br>\n",
    "b) Clients prefered results that are mid-sized. The constant values are 2.5 for the k1 constant and 0.25 for the b constant. <br>\n",
    "c) We discovered our search engine was limited to returing results for exact string matches in the user's query. We decided to stem the uesr queries and our inverted index to provide a wider variety of results. For example, the queries for 'happy' and 'happiness' will return the same results because they both derive from the root 'happi' in our inverted index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "All needed libraries for this search engine to be functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "import bokeh\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Twitter Docs\n",
    "Returns all corpus documents from a given filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwitterDocs(filename):\n",
    "\twith open(filename, 'rb') as csvfile:\n",
    "\t\tr = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "\t\tdocs = [ (x[2], x[4], x[5])  for x in r]\n",
    "\n",
    "\treturn docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stem_tweet(tweet):\n",
    "    stemmed_tweet = \"\"\n",
    "    split_tweet = tweet.split(' ')\n",
    "    for word in split_tweet:\n",
    "        stemmed_tweet += PorterStemmer().stem_word(word) + \" \"\n",
    "    stemmed_tweet = stemmed_tweet.strip(' ')\n",
    "    return stemmed_tweet\n",
    "#print stem_tweet(\"happiness indentifiable\")\n",
    "#print stem_tweet(\"happy indentity\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erase Link\n",
    "This function is part of the normalization effort. A full length tweet will be inserted, and a tweet without a link will be output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def erase_link(tweet):\n",
    "    inx = tweet.find('http')\n",
    "    #Check to see if tweet contains a link\n",
    "    if inx != -1:\n",
    "        #Find white space\n",
    "        sp_inx = tweet.find(\" \", inx)\n",
    "        #Check if there is a white space after the link\n",
    "        if sp_inx != -1:\n",
    "            new_tweet = tweet[0:inx] + tweet[sp_inx + 1:]\n",
    "        else:\n",
    "            new_tweet = tweet[0:inx]\n",
    "        return new_tweet\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize\n",
    "This function will normalize a tweet passed in. The output will be the tweet without any special characters, except a '@,' in all lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(tweet):\n",
    "    #erase link\n",
    "    normalizedTweet = erase_link(tweet)\n",
    "    #print normalizedTweet\n",
    "    normalizedTweet = re.compile('[^a-zA-Z@]').sub(' ', normalizedTweet)\n",
    "    normalizedTweet = normalizedTweet.lower()\n",
    "    normalizedTweet = \" \".join(normalizedTweet.split())\n",
    "    return normalizedTweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the program will open a csv file containing all tweets that will comprise our corpus. Three lists will be created: one for the dates, one for the usernames, and one for the tweets. These three lists are parallel to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"twitter-data/smallData.csv\", 'rb') as csvfile:\n",
    "    r = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    docs = [ (x[2], x[4], x[5])  for x in r]\n",
    "    \n",
    "tweet_date = [ d[0] for d in docs ] #Tweet dates\n",
    "tweet_user = [ d[1] for d in docs ] #Tweet users\n",
    "tweet_text = [ d[2] for d in docs ] #Tweet text\n",
    "\n",
    "#Normalize each tweet \n",
    "tweet_text = map(normalize, tweet_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus \n",
    "This function will generate a corpus as a dictionary. The key value is a the document id, while the value is the date, username, and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_corpus():\n",
    "    corpus = {}\n",
    "    for x in range(0,len(tweet_text)):\n",
    "        corpus[x] = [tweet_date[x], tweet_user[x],tweet_text[x]]\n",
    "        #print corpus[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inverted Indexs\n",
    "\n",
    "For the twitter data, there will be two inverted indexes. The first inverted index will have the username as the key and the tweets that correspond to that username as the values. The second inverted index will be the word index for our tweets; the key will be a word and the values will be the id of the documents that contain that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Dictionary Reversed Index\n",
    "\n",
    "The reversed index for the words in the corpus will be created by going through each word in each document. The reveresed index will allow for a faster retrieval of relevant documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx = {}\n",
    "    \n",
    "    for i, doc in enumerate(corpus):\n",
    "        # Stem document (tweet)\n",
    "        stemmed_document = stem_tweet(doc)\n",
    "        # Iterate through each word in the document\n",
    "        for word in stemmed_document.split():\n",
    "        #for word in doc.split():\n",
    "            if word in idx:\n",
    "                # Update the document's term frequency\n",
    "                if i in idx[word]:\n",
    "                    idx[word][i] += 1\n",
    "                # Add the document to the word index\n",
    "                else:\n",
    "                    idx[word][i] = 1;\n",
    "            # Add the word to the reversed index\n",
    "            else:\n",
    "                idx[word] = {i:1}\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test_users = [\"vcu451\", \"chadfu\", \"SIX15\"]\n",
    "test_corpus = [\"reading my kindle2  love it lee childs is good read\", \n",
    "               \"ok, first assesment of the kindle2 ...it fucking rocks\", \n",
    "               \"fuck this economy I hate aig and their non loan given asses\"]\n",
    "'''\n",
    "\n",
    "idx = create_inverted_index(tweet_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Tweet Index\n",
    "\n",
    "The user tweet index will allow for the all tweets(documents) that belong to a username to be retrieved quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_user_index(users):\n",
    "    \n",
    "    user_tweets = {}\n",
    "    \n",
    "    # Go through each of the tweets in the corpus\n",
    "    for i in range( len(users) ):\n",
    "        # When user already exists, add the document id to the existing user tweet list\n",
    "        if users[i] in user_tweets:\n",
    "            user_tweets[users[i] ].append(i)\n",
    "        # Otherwise, creat a new list with the document id\n",
    "        else:\n",
    "            user_tweets[users[i] ] = [i]\n",
    "            \n",
    "    return user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_tweet_index = create_user_index(tweet_user)\n",
    "\n",
    "#user_tweet_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Document Ranking\n",
    "To rank the documents, we will be implementing two different ranking algorithms: TF-IDF and BM25. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "The TF-IDF (term frequency–inverse document frequency) ranking algorithm ranks documents based on the term frequency of the words in the query in relation to the words in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_results(results, n, head=True):\n",
    "    ''' Helper function to print results\n",
    "    '''\n",
    "    if head:\n",
    "        print('\\nTop %d from recall set of %d items:' % (n, len(results) ) )\n",
    "        for r in results[:n]:\n",
    "            print('\\t%0.2f - %s - %s' % (r[0], r[2],tweet_text[r[1]]))\n",
    "    else:\n",
    "        print('\\nTop %d from recall set of %d items:' % (n, len(results) ) )\n",
    "        for r in results[:n]:\n",
    "            print('\\t%0.2f - %s - %s' % (r[0],r[2], tweet_text[r[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def idf(term, idx, n):\n",
    "    # term - the term that is being scored\n",
    "    # idx - the reversed index on the terms in the corpus\n",
    "    # n - the number of docments the term appears in\n",
    "    return math.log(float(n) / (1 + len(idx[term])))\n",
    "    \n",
    "#print(idf('how', idx, len(tweet_user)))\n",
    "#print(idf('hate', idx, len(tweet_user)))\n",
    "#print(idf('sleep', idx, len(tweet_user)))\n",
    "#print(idf('whoopi', idx, len(tweet_user)))\n",
    "#print(idf('monkeys', idx, len(tweet_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results_tfidf(qry, idx, n):\n",
    "    score = collections.Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                score[doc] += idx[term][doc] * i\n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "    sorted_results= sorted(results, key=lambda t : t[0] * -1)\n",
    "    return sorted_results\n",
    "#results = get_results_tfidf('monkeys', idx, len(tweet_user))\n",
    "#results = get_results_tfidf('hate', idx, len(tweet_user))\n",
    "#results = get_results_tfidf('sleep', idx, len(tweet_user))\n",
    "results = get_results_tfidf('hate', idx, len(tweet_user))\n",
    "\n",
    "#print_results(results, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25\n",
    "Implement the BM25 ranking algorithm to rank our results. This ranking algorithm is the one we will be using for the final version of our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results_bm25(idx, qry, k1=2.5, b=0.25):\n",
    "\n",
    "    score = collections.Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                # f - the number of times the term appears in the document\n",
    "                f = float(idx[term][doc])\n",
    "                # s - the BM25 score for this (term, docuemnt) pair\n",
    "                s = i * ( (f * (k1 + 1) ) / (f + k1 * (1 - b + (b * (float(d[doc] ) / d_avg) ) ) ) )\n",
    "                score[doc] += s\n",
    "                \n",
    "    results = []\n",
    "    for x in [ [r[0], r[1], tweet_user[r[0]] ] for r in zip(score.keys(), score.values() )]:\n",
    "        if x[1] > 0:\n",
    "            results.append([ x[1], x[0], x[2]])\n",
    "            \n",
    "    sorted_results  = sorted(results, key=lambda t: t[0] * -1)\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Effectiveness of BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook, show\n",
    "from bokeh.charts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-banner\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"fb7c4896-e0dd-4b1a-bcbf-73f8fd503b75\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.11.1.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      Bokeh.$(\"#fb7c4896-e0dd-4b1a-bcbf-73f8fd503b75\").text(\"BokehJS successfully loaded\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.11.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"plotdiv\" id=\"7ee63aee-b93f-4d73-9faf-368ca3dad601\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"7ee63aee-b93f-4d73-9faf-368ca3dad601\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '7ee63aee-b93f-4d73-9faf-368ca3dad601' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        Bokeh.$(function() {\n",
       "            var docs_json = {\"59a3c745-029b-4e9e-9e63-f537459f81f1\":{\"roots\":{\"references\":[{\"attributes\":{\"axis_label\":\"score\",\"formatter\":{\"id\":\"68d92fb3-e940-4dff-8ca6-679bee8f08c7\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"19f36585-73f2-4853-8a84-e0d8946bb17f\",\"type\":\"BasicTicker\"}},\"id\":\"9a9e87e8-ff6d-4927-9b9d-6590eea81475\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"bf1c8713-e39d-4dfe-9549-402ec216bde1\",\"type\":\"PreviewSaveTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x_values\",\"y_values\"],\"data\":{\"chart_index\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"x_values\":[7.525055283703363,6.723479617261059,5.9873322139113085,5.676571026338057,5.142724221353287,4.911763552729637,4.872469834509792,4.700656236709738,4.590280461854785,4.371683514316571,4.1113581810481294,3.893346461886598,3.6744180002703004,3.613500058616077,3.2441859924812397,2.9068035198542526,2.7852784832117132,2.6502892190819045,2.2810423585419666,2.110497135473409,2.0623122693667097,2.005089398407589,2.001387239252479,1.9940237836260901,1.9940237836260901,1.870171374705215,1.870171374705215,1.851009782751268,1.851009782751268,1.7665438865370642,1.7608046276464302,1.7608046276464302,1.7438084439818897,1.7438084439818897,1.7107817689064753,1.7000491354754432,1.663522604019556,1.663522604019556,1.663522604019556,1.663522604019556,1.6483444780704724,1.6483444780704724,1.6483444780704724,1.6483444780704724,1.618804254449138,1.618804254449138,1.5627902664059148,1.5362122006507122,1.4979979668036796,1.4979979668036796,1.4856789045766758,1.4856789045766758,1.4856789045766758,1.4616387928521344,1.4616387928521344,1.4616387928521344,1.4270028025001877,1.4270028025001877,1.4158193949570828,1.4158193949570828,1.4158193949570828,1.4158193949570828,1.4158193949570828,1.4158193949570828,1.3624325399436183,1.3522346915907468,1.3522346915907468,1.3522346915907468,1.3522346915907468,1.332290227113007,1.332290227113007,1.332290227113007,1.2941157220381359,1.2941157220381359,1.2941157220381359,1.2941157220381359,1.2941157220381359,1.27583725138788,1.2407867774486523,1.2407867774486523,1.2407867774486523,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.1916791213491014,1.146310626881496,1.146310626881496,1.146310626881496,1.1042698948442773,1.1042698948442773,1.1042698948442773,1.1042698948442773,1.0652037429040317,1.0652037429040317,1.0652037429040317,1.0652037429040317,1.0652037429040317,1.0288072596612972,1.0288072596612972,1.0288072596612972,1.0288072596612972,1.0288072596612972,0.9948158303773337,0.9948158303773337,0.9948158303773337,0.9948158303773337,0.9948158303773337,0.9948158303773337,0.9948158303773337,0.9629986929452226,0.9629986929452226,0.9629986929452226,0.9331536921308046,0.9331536921308046,0.9331536921308046,0.9331536921308046,0.9331536921308046,0.9331536921308046,0.9051029799425038,0.8786894688546878,0.8786894688546878,0.8786894688546878,0.8537738884523808,0.8537738884523808,0.8537738884523808,0.8537738884523808,0.8302323290281423,0.8302323290281423,0.8302323290281423,0.8302323290281423,0.8079541806642387,0.8079541806642387,0.8079541806642387,0.8079541806642387,0.8079541806642387,0.7868403954552428,0.7668020152653812,0.7668020152653812,0.7668020152653812,0.7477589188597837],\"y_values\":[28,5,7,8,10,11,5,12,6,18,20,26,24,19,29,16,28,30,27,3,11,28,20,12,12,14,14,5,5,26,16,16,6,6,17,28,18,18,18,18,7,7,7,7,19,19,8,21,22,22,9,9,9,23,23,23,24,24,10,10,10,10,10,10,26,11,11,11,11,27,27,27,12,12,12,12,12,29,13,13,13,14,14,14,14,14,14,14,14,14,14,15,15,15,16,16,16,16,17,17,17,17,17,18,18,18,18,18,19,19,19,19,19,19,19,20,20,20,21,21,21,21,21,21,22,23,23,23,24,24,24,24,25,25,25,25,26,26,26,26,26,27,28,28,28,29]}},\"id\":\"03473cc6-54a3-4e35-a709-af3ccb63cf65\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"19f36585-73f2-4853-8a84-e0d8946bb17f\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"19f36585-73f2-4853-8a84-e0d8946bb17f\",\"type\":\"BasicTicker\"}},\"id\":\"2339fcc1-68b3-4df8-af03-100636b4cc40\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"9a9e87e8-ff6d-4927-9b9d-6590eea81475\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"e5c96c5f-c8ac-4db9-8474-5d825dfb2d04\",\"type\":\"LinearAxis\"}],\"legend\":null,\"renderers\":[{\"id\":\"3ce69a10-d2ce-4ab5-a55a-7d3e8b9f1fba\",\"type\":\"BoxAnnotation\"},{\"id\":\"f3a1d781-4df7-496d-8491-3144a0d4b8cf\",\"type\":\"GlyphRenderer\"},{\"id\":\"9a9e87e8-ff6d-4927-9b9d-6590eea81475\",\"type\":\"LinearAxis\"},{\"id\":\"e5c96c5f-c8ac-4db9-8474-5d825dfb2d04\",\"type\":\"LinearAxis\"},{\"id\":\"2339fcc1-68b3-4df8-af03-100636b4cc40\",\"type\":\"Grid\"},{\"id\":\"b0933ffd-4c4c-40aa-b4e5-d2506ac7102a\",\"type\":\"Grid\"}],\"title_text_font_size\":{\"value\":\"14pt\"},\"tool_events\":{\"id\":\"1a1c7faa-8c94-4a7d-8a5a-7d329d41b47c\",\"type\":\"ToolEvents\"},\"tools\":[{\"id\":\"52d1c059-05db-430d-afc1-f01b9361b820\",\"type\":\"PanTool\"},{\"id\":\"c7af30fe-255f-4875-b8eb-645dc6c71c6a\",\"type\":\"WheelZoomTool\"},{\"id\":\"d28db97f-5d60-4a09-ae97-06c0cf69ad1f\",\"type\":\"BoxZoomTool\"},{\"id\":\"bf1c8713-e39d-4dfe-9549-402ec216bde1\",\"type\":\"PreviewSaveTool\"},{\"id\":\"43e00229-d7ef-4ae5-8d6a-6906bced6a8c\",\"type\":\"ResizeTool\"},{\"id\":\"1595b14a-cc4f-4a25-9a56-f71304f24cd8\",\"type\":\"ResetTool\"},{\"id\":\"6e7daf93-3c8e-434c-98f0-03a0bbbc4f76\",\"type\":\"HelpTool\"}],\"x_mapper_type\":\"auto\",\"x_range\":{\"id\":\"df264269-8566-4d73-905c-f567ea6b8273\",\"type\":\"Range1d\"},\"xscale\":\"auto\",\"y_mapper_type\":\"auto\",\"y_range\":{\"id\":\"452433ff-cf4c-4494-b98e-41a7ff913973\",\"type\":\"Range1d\"},\"yscale\":\"auto\"},\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"776cc877-d2fe-4f73-acd3-03faefa2389c\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"52d1c059-05db-430d-afc1-f01b9361b820\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"end\":8.202784920187721,\"start\":0.07002928237542583},\"id\":\"df264269-8566-4d73-905c-f567ea6b8273\",\"type\":\"Range1d\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"776cc877-d2fe-4f73-acd3-03faefa2389c\",\"type\":\"BasicTicker\"}},\"id\":\"b0933ffd-4c4c-40aa-b4e5-d2506ac7102a\",\"type\":\"Grid\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.7},\"fill_color\":{\"value\":\"#f22c40\"},\"line_color\":{\"value\":\"#f22c40\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x_values\"},\"y\":{\"field\":\"y_values\"}},\"id\":\"d2d3b253-73d9-4135-a4ac-8615a6614ee2\",\"type\":\"Circle\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"3ce69a10-d2ce-4ab5-a55a-7d3e8b9f1fba\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"84a55f7d-e1d6-48c8-8a96-7f3cfd3f8442\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"68d92fb3-e940-4dff-8ca6-679bee8f08c7\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label\":\"length\",\"formatter\":{\"id\":\"84a55f7d-e1d6-48c8-8a96-7f3cfd3f8442\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"776cc877-d2fe-4f73-acd3-03faefa2389c\",\"type\":\"BasicTicker\"}},\"id\":\"e5c96c5f-c8ac-4db9-8474-5d825dfb2d04\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"1595b14a-cc4f-4a25-9a56-f71304f24cd8\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"end\":32.7,\"start\":0.2999999999999998},\"id\":\"452433ff-cf4c-4494-b98e-41a7ff913973\",\"type\":\"Range1d\"},{\"attributes\":{\"overlay\":{\"id\":\"3ce69a10-d2ce-4ab5-a55a-7d3e8b9f1fba\",\"type\":\"BoxAnnotation\"},\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"d28db97f-5d60-4a09-ae97-06c0cf69ad1f\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"c7af30fe-255f-4875-b8eb-645dc6c71c6a\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1a1c7faa-8c94-4a7d-8a5a-7d329d41b47c\",\"type\":\"ToolEvents\"},{\"attributes\":{\"data_source\":{\"id\":\"03473cc6-54a3-4e35-a709-af3ccb63cf65\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d2d3b253-73d9-4135-a4ac-8615a6614ee2\",\"type\":\"Circle\"},\"hover_glyph\":null,\"nonselection_glyph\":null,\"selection_glyph\":null},\"id\":\"f3a1d781-4df7-496d-8491-3144a0d4b8cf\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"6e7daf93-3c8e-434c-98f0-03a0bbbc4f76\",\"type\":\"HelpTool\"},{\"attributes\":{\"plot\":{\"id\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"subtype\":\"Chart\",\"type\":\"Plot\"}},\"id\":\"43e00229-d7ef-4ae5-8d6a-6906bced6a8c\",\"type\":\"ResizeTool\"}],\"root_ids\":[\"5334f443-a7cf-4721-a17b-f66fc0a769e4\"]},\"title\":\"Bokeh Application\",\"version\":\"0.11.1\"}};\n",
       "            var render_items = [{\"docid\":\"59a3c745-029b-4e9e-9e63-f537459f81f1\",\"elementid\":\"7ee63aee-b93f-4d73-9faf-368ca3dad601\",\"modelid\":\"5334f443-a7cf-4721-a17b-f66fc0a769e4\",\"notebook_comms_target\":\"3d8bb06b-9542-45fb-8edf-4da5dbd316cb\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        });\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><code>&lt;Bokeh Notebook handle for <strong>In[23]</strong>&gt;</code></p>"
      ],
      "text/plain": [
       "<bokeh.io._CommsHandle at 0xba3dda0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = create_inverted_index(tweet_text)\n",
    "results = get_results_bm25(idx, stem_tweet('i hate tomatos'), k1=2.5, b=0.75)\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(tweet_text[x[1]].split()) for x in results]})\n",
    "output_notebook()\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get content based on username\n",
    "This function will retrieve tweets in the corpus that belong to the specified user. These tweets will be ordered by date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 02 04:29:16 UTC 2009 SimpleManJess ncaa baseball super regional rams club\n",
      "Tue Jun 02 04:29:17 UTC 2009 SimpleManJess baseballamerica com blog baseball america prospects blog blog\n"
     ]
    }
   ],
   "source": [
    "def print_results_username(username_index, user_name):\n",
    "    if(user_name in username_index):\n",
    "        # All of the documents that correspond to the username \n",
    "        docs = username_index[user_name]\n",
    "        # For every doc, print date, username, and tweet \n",
    "        for doc in docs:\n",
    "            print tweet_date[doc] + \" \" + tweet_user[doc] + \" \" + tweet_text[doc]\n",
    "    else:\n",
    "        print \"Username does not exist\"\n",
    "    \n",
    "results = create_user_index(tweet_user)\n",
    "print_results_username(results, 'SimpleManJess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine User Query\n",
    "This will take in the user query and determine whether or not the user is wishin to search all tweet content or a specific user's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_query(query):\n",
    "    if(query[0] == '@' and len(query.split()) == 1):\n",
    "        user_choice = raw_input((\"Select your query preference\",\n",
    "                                \"\\n1. All content\",\n",
    "                                \"\\n2. User content\"))\n",
    "        return user_choice\n",
    "    return '1'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def u_search(user_choice, query, idx, user_idx):\n",
    "    if(user_choice == '1'):\n",
    "\t\tquery = normalize(query)\n",
    "\n",
    "\t\tresults = get_results_bm25(idx, query, 2.5, 0.25)\n",
    "\t\tprint_results(results,25)\n",
    "\n",
    "    if(user_choice == '2'):\n",
    "\t\tquery = query[1:]\n",
    "\t\tprint_results_username(user_idx, query)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "input = raw_input(\"Enter \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query (@ to quit): love\n",
      "\n",
      "Top 25 from recall set of 32 items:\n",
      "\t5.68 - Jen2Squared - @faithbabywear ooooh what model are you getting i have the d and love love love love it\n",
      "\t5.27 - ashpeckham - just got my new toy canon d love love love it\n",
      "\t4.01 - GrfxGuru - @mitzs hey bud np i do so love my d although i d love a d mkii more\n",
      "\t3.20 - PJ_King - loves twitter\n",
      "\t3.15 - mtgillikin - i love lebron\n",
      "\t3.00 - angelkim17 - @dannygokey i love you danny gokey\n",
      "\t3.00 - MzJill - i loved night at the museum\n",
      "\t2.96 - GoodPhoenix - am loving new malcolm gladwell book outliers\n",
      "\t2.96 - HappyWino - my kindle came and i love it\n",
      "\t2.87 - jackdaniels08 - @googleio yay happy place place place i love google\n",
      "\t2.83 - vcu451 - reading my kindle love it lee childs is good read\n",
      "\t2.83 - ManiKarthik - @arunbasillal i love google translator too d good day mate\n",
      "\t2.79 - mandanicole - how can you not love obama he makes jokes about himself\n",
      "\t2.68 - imusicmash - rt @jessverr i love the nerdy stanford human biology videos makes me miss school\n",
      "\t2.64 - jeffswhite - i m really loving the new search site wolfram alpha makes google seem so quaint\n",
      "\t2.64 - LoonyLongbottom - @iheartseverus we love you too and don t want you to die latex the devil\n",
      "\t2.57 - dustinrowley - top ten most watched on viral video chart love the nike mostvaluablepuppets campaign from wieden amp kennedy\n",
      "\t2.54 - vincentx24x - dear nike stop with the flywire that shit is a waste of science and ugly love @vincentx x\n",
      "\t2.54 - k8tb52 - i love my kindle no more stacks of books to trip over on the way to the loo\n",
      "\t2.54 - roguemovement - using linux and loving it so much nicer than windows looking forward to using the wysiwyg latex editor\n",
      "\t2.51 - princezzcutz - @sketchbug lebron is a hometown hero to me lol i love the lakers but let s go cavs lol\n",
      "\t2.51 - CrownRoyal8 - i love dwight howard s vitamin water commercial now i wish he was with nike and not adidas lol\n",
      "\t2.51 - Pas_de_Cheval - saw the new night at the museum and i loved it next is to go see up in d\n",
      "\t2.42 - nyctimes - i still love my kindle but reading the new york times on it does not feel natural i miss the bloomingdale ads\n",
      "\t2.30 - A_TALL_BLONDE - i lam so in love with bobby flay he is my favorite rt @terrysimpson @bflay you need a place in phoenix we have great peppers here\n",
      "\n",
      "Enter Query (@ to quit): \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7e86c98e4460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Run the search engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-7e86c98e4460>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"@\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mstemmed_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstem_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mchoice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmed_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mu_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstemmed_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fb24558a490b>\u001b[0m in \u001b[0;36mdetermine_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetermine_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'@'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         user_choice = raw_input((\"Select your query preference\",\n\u001b[0;32m      4\u001b[0m                                 \u001b[1;34m\"\\n1. All content\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \"\\n2. User content\"))\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# The main function that will run the search engine\n",
    "def main():\n",
    "    query = \"\"\n",
    "    idx = create_inverted_index(tweet_text)\n",
    "    user_idx = create_user_index(tweet_user)\n",
    "    # Keep asking for a query until the user enters an \"@\" sign\n",
    "    while query != \"@\":\n",
    "        query = raw_input(\"Enter Query (@ to quit): \" )\n",
    "        if (query != \"@\"):\n",
    "            stemmed_query = stem_tweet(query)\n",
    "            choice = determine_query(stemmed_query)\n",
    "            u_search(choice, stemmed_query, idx, user_idx)\n",
    "        print (\"\")\n",
    "\n",
    "# Get the name of the file to use for data\n",
    "#filename = raw_input(\"Enter data filename: \")\n",
    "\n",
    "# Read in the data from the csv file\n",
    "docs = getTwitterDocs(\"twitter-data/smallData.csv\")\n",
    "\n",
    "# Create the lists that contain the tweet info\n",
    "tweet_date = [ d[0] for d in docs ] #Tweet dates\n",
    "tweet_user = [ d[1] for d in docs ] #Tweet users\n",
    "tweet_text = [ d[2] for d in docs ] #Tweet text\n",
    "\n",
    "#Normalize each tweet \n",
    "tweet_text = map(normalize, tweet_text)\n",
    "\n",
    "# n - the length of the corpus\n",
    "n = len(tweet_text)\n",
    "\n",
    "# d - list with elements corresponding to the length of each document\n",
    "d = [len(x.split()) for x in tweet_text]\n",
    "\n",
    "# d_avg - the average document length of the docuemnts in the corpus\n",
    "d_avg = float(sum(d) / len(d))\n",
    "\n",
    "# Run the search engine\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
